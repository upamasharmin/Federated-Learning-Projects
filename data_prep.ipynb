{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niloy\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# flower\n",
    "import flwr as fl\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'attention_numeric.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "\n",
    "train_df = df[:3200]\n",
    "test_df = df[3200:]\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df, split='train')\n",
    "test_ds = Dataset.from_pandas(test_df, split='test')\n",
    "\n",
    "# main_dataset = load_dataset(\"csv\", data_files=data_file)\n",
    "# main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_of_face': Value(dtype='int64', id=None),\n",
       " 'face_x': Value(dtype='float64', id=None),\n",
       " 'face_y': Value(dtype='float64', id=None),\n",
       " 'face_w': Value(dtype='float64', id=None),\n",
       " 'face_h': Value(dtype='float64', id=None),\n",
       " 'face_con': Value(dtype='float64', id=None),\n",
       " 'no_of_hand': Value(dtype='int64', id=None),\n",
       " 'pose': Value(dtype='int64', id=None),\n",
       " 'pose_x': Value(dtype='float64', id=None),\n",
       " 'pose_y': Value(dtype='float64', id=None),\n",
       " 'phone': Value(dtype='int64', id=None),\n",
       " 'phone_x': Value(dtype='int64', id=None),\n",
       " 'phone_y': Value(dtype='int64', id=None),\n",
       " 'phone_w': Value(dtype='int64', id=None),\n",
       " 'phone_h': Value(dtype='int64', id=None),\n",
       " 'phone_con': Value(dtype='float64', id=None),\n",
       " 'label': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioner = IidPartitioner(num_partitions=10)\n",
    "\n",
    "partitioner.dataset = train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['no_of_face', 'face_x', 'face_y', 'face_w', 'face_h', 'face_con', 'no_of_hand', 'pose', 'pose_x', 'pose_y', 'phone', 'phone_x', 'phone_y', 'phone_w', 'phone_h', 'phone_con', 'label'],\n",
       "    num_rows: 320\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioner.load_partition(partition_id=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "trainloaders = []\n",
    "valloaders = []\n",
    "for partition_id in range(NUM_CLIENTS):\n",
    "    partition = partitioner.load_partition(partition_id)\n",
    "    \n",
    "    partition = partition.train_test_split(train_size=0.8, seed=42)\n",
    "    trainloaders.append(DataLoader(partition[\"train\"], batch_size=BATCH_SIZE))\n",
    "    valloaders.append(DataLoader(partition[\"test\"], batch_size=BATCH_SIZE))\n",
    "\n",
    "testloader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_of_face': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'face_x': tensor([203.4054, 270.3198, 280.1867, 325.8162, 267.7397, 302.9323, 178.5900,\n",
       "         343.6002, 257.8106, 305.7684, 251.1568, 178.7871, 180.6091, 307.8918,\n",
       "         221.7130, 198.0118, 314.1122, 312.4948, 326.6386, 306.9357, 341.2012,\n",
       "         345.9195, 327.8390, 215.0534,   0.0000, 310.2180, 273.5754, 251.9702,\n",
       "         179.9767, 205.0999, 303.3341, 332.0424], dtype=torch.float64),\n",
       " 'face_y': tensor([195.3048, 274.9657, 239.2570, 369.4451, 114.9439, 278.4474, 217.9682,\n",
       "         269.0542, 224.3967, 277.0767, 275.3308, 124.4607, 222.5235, 276.6091,\n",
       "         241.2522, 181.9824, 277.5124, 277.5345, 367.4226, 225.9265, 357.5038,\n",
       "         363.5866, 353.3090, 224.9158,   0.0000, 298.3477, 254.5960, 204.2641,\n",
       "         223.2516, 229.2937, 285.7629, 285.2076], dtype=torch.float64),\n",
       " 'face_w': tensor([138.5814, 164.1431, 157.8290, 169.1203, 238.8236, 173.5847, 354.4392,\n",
       "         131.1015, 128.1010, 160.8729, 176.8806, 305.0622, 378.6771, 163.2825,\n",
       "         161.9854, 129.8797, 159.8720, 159.1735, 182.7674, 122.8106, 164.1946,\n",
       "         167.3021, 178.1342, 159.5070,   0.0000, 175.2316, 154.5731, 117.1014,\n",
       "         367.8928, 147.8092, 168.8797, 137.4685], dtype=torch.float64),\n",
       " 'face_h': tensor([138.5817, 164.1428, 157.8267, 169.1139, 238.8016, 173.5820, 354.4093,\n",
       "         131.1018, 128.1012, 160.8727, 176.8805, 305.0270, 378.6704, 163.2824,\n",
       "         161.9853, 129.8799, 159.8720, 159.1735, 182.7541, 122.8109, 164.1896,\n",
       "         167.2968, 178.1279, 159.5068,   0.0000, 175.2312, 154.5722, 117.1018,\n",
       "         367.8663, 147.8092, 168.8783, 137.4680], dtype=torch.float64),\n",
       " 'face_con': tensor([89.0157, 81.6446, 65.3696, 73.3476, 67.8104, 70.5519, 65.5927, 81.5314,\n",
       "         94.3474, 93.1510, 71.1713, 56.8131, 64.4867, 92.1414, 91.2592, 90.7882,\n",
       "         87.5909, 91.7785, 71.4335, 96.1627, 78.6087, 75.7984, 73.0838, 89.2301,\n",
       "          0.0000, 91.5262, 85.6441, 85.3463, 62.8114, 88.5095, 72.0052, 84.1052],\n",
       "        dtype=torch.float64),\n",
       " 'no_of_hand': tensor([0, 2, 2, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0]),\n",
       " 'pose': tensor([0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 3, 3, 1, 1, 2, 1, 0, 0, 0, 2,\n",
       "         0, 1, 0, 1, 0, 1, 0, 0]),\n",
       " 'pose_x': tensor([-15.0000, -15.0000, -15.0000,  10.8437, -12.3202, -15.0000, -15.0000,\n",
       "           9.8726,  10.6983,   6.5289, -15.0000, -15.0000, -15.0000,   7.3147,\n",
       "           5.1935,  10.4749,   8.6227,   7.2281,  11.3967,   5.9786, -15.0000,\n",
       "         -15.0000, -15.0000,  -1.8352, -15.0000,   6.4281, -15.0000,  12.5106,\n",
       "         -15.0000,  12.4054, -15.0000, -15.0000], dtype=torch.float64),\n",
       " 'pose_y': tensor([ 10.0000,  10.0000,  10.0000, -12.3855,  -4.5866,  10.0000,  10.0000,\n",
       "           5.5290,  13.6266,  10.9489,  10.0000,  10.0000,  10.0000,  10.5773,\n",
       "          16.8178,  26.1631,  -9.8774,   3.0442, -12.8397,   2.6332,  10.0000,\n",
       "          10.0000,  10.0000, -14.3933,  10.0000,  -1.5869,  10.0000,  14.4511,\n",
       "          10.0000,  11.1742,  10.0000,  10.0000], dtype=torch.float64),\n",
       " 'phone': tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 1, 0, 0]),\n",
       " 'phone_x': tensor([  0,   0,   0,   0, 162,   0,   0,   0, 202,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 160,\n",
       "           0,   0,   0,   0]),\n",
       " 'phone_y': tensor([  0,   0,   0,   0, 286,   0,   0,   0, 400,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 214,\n",
       "           0, 241,   0,   0]),\n",
       " 'phone_w': tensor([  0,   0,   0,   0, 306,   0,   0,   0, 333,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 265,\n",
       "           0, 150,   0,   0]),\n",
       " 'phone_h': tensor([  0,   0,   0,   0, 480,   0,   0,   0, 480,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 351,\n",
       "           0, 476,   0,   0]),\n",
       " 'phone_con': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.8801, 0.0000, 0.0000, 0.0000, 0.7898,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.7436, 0.0000, 0.6784, 0.0000, 0.0000], dtype=torch.float64),\n",
       " 'label': tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "         1, 0, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainloaders[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'no_of_face': batch['no_of_face'],\n",
    "    'face_x': batch['face_x'],\n",
    "    'face_y': batch['face_y'],\n",
    "    'face_w': batch['face_w'],\n",
    "    'face_h': batch['face_h'],\n",
    "    'face_con': batch['face_con'],\n",
    "    'no_of_hand': batch['no_of_hand'],\n",
    "    'pose': batch['pose'],\n",
    "    'pose_x': batch['pose_x'],\n",
    "    'pose_y': batch['pose_y'],\n",
    "    'phone': batch['phone'],\n",
    "    'phone_x': batch['phone_x'],\n",
    "    'phone_y': batch['phone_y'],\n",
    "    'phone_w': batch['phone_w'],\n",
    "    'phone_h': batch['phone_h'],\n",
    "    'phone_con': batch['phone_con']\n",
    "}\n",
    "\n",
    "labels = batch['label']\n",
    "\n",
    "# # Example of processing the features and labels\n",
    "# print(\"Features:\")\n",
    "# for key, value in features.items():\n",
    "#     print(f\"{key}: {value}\")\n",
    "\n",
    "# print(\"Labels:\")\n",
    "# print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class attentionNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_1 = nn.Linear(16, 80)\n",
    "        self.act_1 = nn.ReLU()\n",
    "        \n",
    "        self.hidden_2 = nn.Linear(80, 400)\n",
    "        self.act_2 = nn.ReLU()\n",
    "        \n",
    "        self.hidden_3 = nn.Linear(400, 80)\n",
    "        self.act_3 = nn.ReLU()\n",
    "        \n",
    "        self.hidden_4 = nn.Linear(80,16)\n",
    "        self.act_4 = nn.ReLU()\n",
    "        \n",
    "        self.out = nn.Linear(16, 1)\n",
    "        self.act_out = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act_1(self.hidden_1(x))\n",
    "        x = self.act_2(self.hidden_2(x))\n",
    "        x = self.act_3(self.hidden_3(x))\n",
    "        x = self.act_4(self.hidden_4(x))\n",
    "        x = self.act_out(self.out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the training function\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in next(iter(trainloaders[0])):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Define the testing function\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.round()\n",
    "            correct += (preds == labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
